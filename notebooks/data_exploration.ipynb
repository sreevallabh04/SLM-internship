{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Exploration - IMDb Sentiment Analysis\n",
        "\n",
        "This notebook contains exploratory data analysis of the IMDb movie reviews dataset for sentiment classification.\n",
        "\n",
        "## Objectives\n",
        "- Load and examine the IMDb dataset structure\n",
        "- Analyze text characteristics and distributions\n",
        "- Visualize class balance and text statistics\n",
        "- Identify preprocessing requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Starting IMDb dataset exploration...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the IMDb dataset\n",
        "print(\"Loading IMDb dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Basic dataset information\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Training samples: {len(dataset['train']):,}\")\n",
        "print(f\"Test samples: {len(dataset['test']):,}\")\n",
        "print(f\"Total samples: {len(dataset['train']) + len(dataset['test']):,}\")\n",
        "\n",
        "# Dataset features\n",
        "print(f\"\\nDataset features: {list(dataset['train'].features.keys())}\")\n",
        "print(f\"Label mapping: {dataset['train'].features['label']}\")\n",
        "\n",
        "# Convert to pandas for easier analysis\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(f\"\\nTrain DataFrame shape: {train_df.shape}\")\n",
        "print(f\"Test DataFrame shape: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution analysis\n",
        "print(\"Class Distribution Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Train set class distribution\n",
        "train_counts = train_df['label'].value_counts().sort_index()\n",
        "test_counts = test_df['label'].value_counts().sort_index()\n",
        "\n",
        "print(\"Training Set:\")\n",
        "for label, count in train_counts.items():\n",
        "    sentiment = \"Negative\" if label == 0 else \"Positive\"\n",
        "    percentage = (count / len(train_df)) * 100\n",
        "    print(f\"  {sentiment}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "for label, count in test_counts.items():\n",
        "    sentiment = \"Negative\" if label == 0 else \"Positive\"\n",
        "    percentage = (count / len(test_df)) * 100\n",
        "    print(f\"  {sentiment}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Train distribution\n",
        "train_labels = ['Negative', 'Positive']\n",
        "train_values = [train_counts[0], train_counts[1]]\n",
        "axes[0].pie(train_values, labels=train_labels, autopct='%1.1f%%', startangle=90)\n",
        "axes[0].set_title('Training Set Class Distribution')\n",
        "\n",
        "# Test distribution\n",
        "test_values = [test_counts[0], test_counts[1]]\n",
        "axes[1].pie(test_values, labels=train_labels, autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Test Set Class Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Dataset is perfectly balanced!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text length analysis\n",
        "print(\"Text Length Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Calculate text lengths\n",
        "train_df['text_length'] = train_df['text'].str.len()\n",
        "test_df['text_length'] = test_df['text'].str.len()\n",
        "\n",
        "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
        "test_df['word_count'] = test_df['text'].str.split().str.len()\n",
        "\n",
        "# Statistics\n",
        "print(\"Training Set Statistics:\")\n",
        "print(f\"  Avg characters: {train_df['text_length'].mean():.1f}\")\n",
        "print(f\"  Avg words: {train_df['word_count'].mean():.1f}\")\n",
        "print(f\"  Max characters: {train_df['text_length'].max():,}\")\n",
        "print(f\"  Max words: {train_df['word_count'].max():,}\")\n",
        "\n",
        "print(\"\\nTest Set Statistics:\")\n",
        "print(f\"  Avg characters: {test_df['text_length'].mean():.1f}\")\n",
        "print(f\"  Avg words: {test_df['word_count'].mean():.1f}\")\n",
        "print(f\"  Max characters: {test_df['text_length'].max():,}\")\n",
        "print(f\"  Max words: {test_df['word_count'].max():,}\")\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Character length distribution\n",
        "axes[0,0].hist(train_df['text_length'], bins=50, alpha=0.7, label='Train', density=True)\n",
        "axes[0,0].hist(test_df['text_length'], bins=50, alpha=0.7, label='Test', density=True)\n",
        "axes[0,0].set_title('Character Length Distribution')\n",
        "axes[0,0].set_xlabel('Characters')\n",
        "axes[0,0].set_ylabel('Density')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# Word count distribution\n",
        "axes[0,1].hist(train_df['word_count'], bins=50, alpha=0.7, label='Train', density=True)\n",
        "axes[0,1].hist(test_df['word_count'], bins=50, alpha=0.7, label='Test', density=True)\n",
        "axes[0,1].set_title('Word Count Distribution')\n",
        "axes[0,1].set_xlabel('Words')\n",
        "axes[0,1].set_ylabel('Density')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# Box plots by sentiment\n",
        "combined_df = pd.concat([\n",
        "    train_df[['text_length', 'word_count', 'label']],\n",
        "    test_df[['text_length', 'word_count', 'label']]\n",
        "])\n",
        "\n",
        "sns.boxplot(data=combined_df, x='label', y='text_length', ax=axes[1,0])\n",
        "axes[1,0].set_title('Character Length by Sentiment')\n",
        "axes[1,0].set_xticklabels(['Negative', 'Positive'])\n",
        "\n",
        "sns.boxplot(data=combined_df, x='label', y='word_count', ax=axes[1,1])\n",
        "axes[1,1].set_title('Word Count by Sentiment')\n",
        "axes[1,1].set_xticklabels(['Negative', 'Positive'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 1450] Insufficient system resources exist to complete the requested service",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall matplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\packaging.py:92\u001b[0m, in \u001b[0;36mPackagingMagics.pip\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     python \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39mquote(python)\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpython\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: you may need to restart the kernel to use updated packages.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py:655\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    654\u001b[0m             cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpushd \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m &&\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcmd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_expand(cmd, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\utils\\_process_win32.py:124\u001b[0m, in \u001b[0;36msystem\u001b[1;34m(cmd)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpushd \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m &&\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (path, cmd)\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_system_body\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\utils\\_process_common.py:85\u001b[0m, in \u001b[0;36mprocess_handler\u001b[1;34m(cmd, callback, stderr)\u001b[0m\n\u001b[0;32m     77\u001b[0m p \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd, shell\u001b[38;5;241m=\u001b[39mshell,\n\u001b[0;32m     78\u001b[0m                      executable\u001b[38;5;241m=\u001b[39mexecutable,\n\u001b[0;32m     79\u001b[0m                      stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m     80\u001b[0m                      stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[0;32m     81\u001b[0m                      stderr\u001b[38;5;241m=\u001b[39mstderr,\n\u001b[0;32m     82\u001b[0m                      close_fds\u001b[38;5;241m=\u001b[39mclose_fds)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^C\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\utils\\_process_win32.py:97\u001b[0m, in \u001b[0;36m_system_body\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m     95\u001b[0m result \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 1450] Insufficient system resources exist to complete the requested service"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.58.4-cp312-cp312-win_amd64.whl.metadata (108 kB)\n",
            "     ---------------------------------------- 0.0/108.7 kB ? eta -:--:--\n",
            "     ---------------------------------------- 0.0/108.7 kB ? eta -:--:--\n",
            "     --- ------------------------------------ 10.2/108.7 kB ? eta -:--:--\n",
            "     ---------- -------------------------- 30.7/108.7 kB 325.1 kB/s eta 0:00:01\n",
            "     -------------------- ---------------- 61.4/108.7 kB 465.5 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 102.4/108.7 kB 737.3 kB/s eta 0:00:01\n",
            "     --------------------------------- -- 102.4/108.7 kB 737.3 kB/s eta 0:00:01\n",
            "     ------------------------------------ 108.7/108.7 kB 394.0 kB/s eta 0:00:00\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sriva\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Using cached matplotlib-3.10.3-cp312-cp312-win_amd64.whl (8.1 MB)\n",
            "Downloading fonttools-4.58.4-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.1/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ---- ----------------------------------- 0.3/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 0.4/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 0.5/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 0.6/2.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 0.7/2.2 MB 2.3 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 0.8/2.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.0/2.2 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 1.1/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 1.2/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.3/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.5/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.7/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.8/2.2 MB 2.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.9/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.1/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 1.9 MB/s eta 0:00:00\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "Successfully installed fonttools-4.58.4 matplotlib-3.10.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\sriva\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grad-cam 1.5.5 requires scikit-learn, which is not installed.\n",
            "music21 9.5.0 requires chardet, which is not installed.\n",
            "music21 9.5.0 requires more-itertools, which is not installed.\n",
            "gradio 4.27.0 requires typer<1.0,>=0.12; sys_platform != \"emscripten\", but you have typer 0.9.0 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Exploration\n",
        "\n",
        "This notebook contains exploratory data analysis of the sentiment analysis dataset.\n",
        "\n",
        "## Dataset Overview\n",
        "- IMDb movie reviews dataset\n",
        "- Binary sentiment classification (positive/negative)\n",
        "- Text preprocessing and statistics analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the IMDb dataset\n",
        "print(\"Loading IMDb dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Basic dataset information\n",
        "print(f\"Training samples: {len(dataset['train'])}\")\n",
        "print(f\"Test samples: {len(dataset['test'])}\")\n",
        "print(f\"Features: {dataset['train'].features}\")\n",
        "\n",
        "# Convert to pandas for easier analysis\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(train_df.head())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
