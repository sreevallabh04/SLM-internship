{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Exploration - IMDb Sentiment Analysis\n",
        "\n",
        "This notebook contains exploratory data analysis of the IMDb movie reviews dataset for sentiment classification.\n",
        "\n",
        "## Objectives\n",
        "- Load and examine the IMDb dataset structure\n",
        "- Analyze text characteristics and distributions\n",
        "- Visualize class balance and text statistics\n",
        "- Identify preprocessing requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üì¶ Libraries imported successfully\")\n",
        "print(\"üéØ Starting IMDb dataset exploration...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the IMDb dataset\n",
        "print(\"üì• Loading IMDb dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Basic dataset information\n",
        "print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"üìä Training samples: {len(dataset['train']):,}\")\n",
        "print(f\"üìä Test samples: {len(dataset['test']):,}\")\n",
        "print(f\"üìä Total samples: {len(dataset['train']) + len(dataset['test']):,}\")\n",
        "\n",
        "# Dataset features\n",
        "print(f\"\\nüîç Dataset features: {list(dataset['train'].features.keys())}\")\n",
        "print(f\"üé≠ Label mapping: {dataset['train'].features['label']}\")\n",
        "\n",
        "# Convert to pandas for easier analysis\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(f\"\\nüìã Train DataFrame shape: {train_df.shape}\")\n",
        "print(f\"üìã Test DataFrame shape: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution analysis\n",
        "print(\"üé≠ Class Distribution Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Train set class distribution\n",
        "train_counts = train_df['label'].value_counts().sort_index()\n",
        "test_counts = test_df['label'].value_counts().sort_index()\n",
        "\n",
        "print(\"Training Set:\")\n",
        "for label, count in train_counts.items():\n",
        "    sentiment = \"Negative\" if label == 0 else \"Positive\"\n",
        "    percentage = (count / len(train_df)) * 100\n",
        "    print(f\"  {sentiment}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nTest Set:\")\n",
        "for label, count in test_counts.items():\n",
        "    sentiment = \"Negative\" if label == 0 else \"Positive\"\n",
        "    percentage = (count / len(test_df)) * 100\n",
        "    print(f\"  {sentiment}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Train distribution\n",
        "train_labels = ['Negative', 'Positive']\n",
        "train_values = [train_counts[0], train_counts[1]]\n",
        "axes[0].pie(train_values, labels=train_labels, autopct='%1.1f%%', startangle=90)\n",
        "axes[0].set_title('Training Set Class Distribution')\n",
        "\n",
        "# Test distribution\n",
        "test_values = [test_counts[0], test_counts[1]]\n",
        "axes[1].pie(test_values, labels=train_labels, autopct='%1.1f%%', startangle=90)\n",
        "axes[1].set_title('Test Set Class Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Dataset is perfectly balanced!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text length analysis\n",
        "print(\"üìù Text Length Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Calculate text lengths\n",
        "train_df['text_length'] = train_df['text'].str.len()\n",
        "test_df['text_length'] = test_df['text'].str.len()\n",
        "\n",
        "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
        "test_df['word_count'] = test_df['text'].str.split().str.len()\n",
        "\n",
        "# Statistics\n",
        "print(\"Training Set Statistics:\")\n",
        "print(f\"  Avg characters: {train_df['text_length'].mean():.1f}\")\n",
        "print(f\"  Avg words: {train_df['word_count'].mean():.1f}\")\n",
        "print(f\"  Max characters: {train_df['text_length'].max():,}\")\n",
        "print(f\"  Max words: {train_df['word_count'].max():,}\")\n",
        "\n",
        "print(\"\\nTest Set Statistics:\")\n",
        "print(f\"  Avg characters: {test_df['text_length'].mean():.1f}\")\n",
        "print(f\"  Avg words: {test_df['word_count'].mean():.1f}\")\n",
        "print(f\"  Max characters: {test_df['text_length'].max():,}\")\n",
        "print(f\"  Max words: {test_df['word_count'].max():,}\")\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Character length distribution\n",
        "axes[0,0].hist(train_df['text_length'], bins=50, alpha=0.7, label='Train', density=True)\n",
        "axes[0,0].hist(test_df['text_length'], bins=50, alpha=0.7, label='Test', density=True)\n",
        "axes[0,0].set_title('Character Length Distribution')\n",
        "axes[0,0].set_xlabel('Characters')\n",
        "axes[0,0].set_ylabel('Density')\n",
        "axes[0,0].legend()\n",
        "\n",
        "# Word count distribution\n",
        "axes[0,1].hist(train_df['word_count'], bins=50, alpha=0.7, label='Train', density=True)\n",
        "axes[0,1].hist(test_df['word_count'], bins=50, alpha=0.7, label='Test', density=True)\n",
        "axes[0,1].set_title('Word Count Distribution')\n",
        "axes[0,1].set_xlabel('Words')\n",
        "axes[0,1].set_ylabel('Density')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# Box plots by sentiment\n",
        "combined_df = pd.concat([\n",
        "    train_df[['text_length', 'word_count', 'label']],\n",
        "    test_df[['text_length', 'word_count', 'label']]\n",
        "])\n",
        "\n",
        "sns.boxplot(data=combined_df, x='label', y='text_length', ax=axes[1,0])\n",
        "axes[1,0].set_title('Character Length by Sentiment')\n",
        "axes[1,0].set_xticklabels(['Negative', 'Positive'])\n",
        "\n",
        "sns.boxplot(data=combined_df, x='label', y='word_count', ax=axes[1,1])\n",
        "axes[1,1].set_title('Word Count by Sentiment')\n",
        "axes[1,1].set_xticklabels(['Negative', 'Positive'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Exploration\n",
        "\n",
        "This notebook contains exploratory data analysis of the sentiment analysis dataset.\n",
        "\n",
        "## Dataset Overview\n",
        "- IMDb movie reviews dataset\n",
        "- Binary sentiment classification (positive/negative)\n",
        "- Text preprocessing and statistics analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the IMDb dataset\n",
        "print(\"Loading IMDb dataset...\")\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Basic dataset information\n",
        "print(f\"Training samples: {len(dataset['train'])}\")\n",
        "print(f\"Test samples: {len(dataset['test'])}\")\n",
        "print(f\"Features: {dataset['train'].features}\")\n",
        "\n",
        "# Convert to pandas for easier analysis\n",
        "train_df = pd.DataFrame(dataset['train'])\n",
        "test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(train_df.head())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
